{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomended emoji:  ðŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "#William Dahl\n",
    "#CSI 436\n",
    "#Final Project\n",
    "#May 9th, 2019\n",
    "\n",
    "#This is a a Emoji recomendation app that uses Linear SVM to recomend emojis to a user based on a given message\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tkinter import *\n",
    "import numpy as np\n",
    "\n",
    "#creates our model and our Vectorizer to be used\n",
    "model =  LinearSVC(max_iter=10000)\n",
    "vector = DictVectorizer()\n",
    "\n",
    "#breaks mesages down into tokens of a specific length\n",
    "def tokens(mesg, length):\n",
    "    words = mesg.split()\n",
    "    phrases = []\n",
    "    for i in range(length-1, len(words)): \n",
    "        phrase = ' '.join(words[i-length+1:i+1])\n",
    "        phrases.append(phrase) \n",
    "        \n",
    "    return phrases\n",
    "\n",
    "#gives lables to each of the classes of the messages int he data\n",
    "def classify(label):\n",
    "    #our lables\n",
    "    feelings = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "    clas = \"\"\n",
    "    #maps the vector from strings to floats\n",
    "    lables = list(map(float, label.split()))\n",
    "    #maps the vectors to their respective class\n",
    "    for i in range(len(lables)): \n",
    "        if lables[i] == 1: \n",
    "            clas += feelings[i] + \" \"\n",
    "\n",
    "    return clas\n",
    "\n",
    "#extracts the features from each message in the form of n-grams\n",
    "def getFeatures(mesg):\n",
    "    mesg = mesg.lower()\n",
    "    features = [] #holds a list of the extracted features\n",
    "    #makes 2-gram to 4-grams form the message\n",
    "    for i in range(1, 5): \n",
    "        features += tokens(mesg, i)\n",
    "\n",
    "    #Makes 1-grams from the message\n",
    "    features += tokens(mesg, 1)\n",
    "    #returns the features as dictinary with the n-gram as the keys\n",
    "    #and the number of times it appears in other n-grams extracted from the message as the value\n",
    "    return Counter(features)\n",
    "\n",
    "#recomends a emoji to the user based on thier input\n",
    "def Recomend_Emoji():\n",
    "    global model #imports our model\n",
    "    global vector #imports are vectorizer\n",
    "    #mapping from the class to a emoji\n",
    "    emoji_map = {\"joy \":\"ðŸ˜‚\", \"fear \":\"ðŸ˜±\", \"anger \":\"ðŸ˜ \", \"sadness \":\"ðŸ˜¢\", \"disgust \":\"ðŸ˜’\", \"shame \":\"ðŸ˜³\", \"guilt \":\"ðŸ˜³\"}\n",
    "    mesg_dict = getFeatures(mesg.get()) #gets features of the message\n",
    "    mesg_dict = vector.transform(mesg_dict) #vectorizes the features\n",
    "    emoji = model.predict(mesg_dict)[0]#predicts the entiment\n",
    "    print(\"Recomended emoji: \", emoji_map[emoji])#writes the recomended emoji out\n",
    "\n",
    "#Checks if the file model.sav exsists\n",
    "config = Path('model.sav')\n",
    "#if so it imports the model and the vetorizer form the respective files\n",
    "if config.is_file():\n",
    "    model = pickle.load(open(\"model.sav\", 'rb'))\n",
    "    vector = pickle.load(open(\"vector.sav\", 'rb'))\n",
    "\n",
    "#other wise it begeins traingin the model and the vectorizer\n",
    "else:\n",
    "    mesgs = [] #messges\n",
    "    classes = [] #classes of the messages\n",
    "    data  = [] #data matrix\n",
    "    \n",
    "    #reads the data file\n",
    "    for line in open(\"data.txt\", 'r'): \n",
    "        mesg = line[line.find(\"]\")+1:]\n",
    "        clas = ' '.join(line[1:line.find(\"]\")].split())\n",
    "        data.append([clas, mesg])\n",
    "    \n",
    "    #creates a list of dictanaries with n-grams in it for each message\n",
    "    #creates a vector of labels for each message\n",
    "    for clas, mesg in data:\n",
    "        mesgs.append(getFeatures(mesg))\n",
    "        classes.append(classify(clas))\n",
    "\n",
    "    #splits the training and testing set\n",
    "    mesgs_train, mesgs_test, classes_train, classes_test = train_test_split(mesgs, classes, test_size = 0.2)\n",
    "    #fits the vectorizer to the training data\n",
    "    mesgs_train = vector.fit_transform(mesgs_train)\n",
    "    #vectorizes the testing data\n",
    "    mesgs_test = vector.transform(mesgs_test)\n",
    "    #fits the model with the training data\n",
    "    model.fit(mesgs_train, classes_train)\n",
    "    #gets the accuracy of the model\n",
    "    score = accuracy_score(classes_test, model.predict(mesgs_test))\n",
    "    print(\"testing accuracy:\", score)\n",
    "\n",
    "    #re fits the model with all of the data \n",
    "    model.fit(vector.fit_transform(mesgs), classes)\n",
    "    #dumps the files modle.sava and vector.sav with the model and the vectorizer respectivly\n",
    "    pickle.dump(model, open(\"model.sav\", 'wb'))\n",
    "    pickle.dump(vector, open(\"vector.sav\", 'wb'))\n",
    "\n",
    "#Creates the GUI for the user to input their message.  \n",
    "master = Tk()\n",
    "Label(master, text=\"Enter your message:\").grid(row=0)\n",
    "\n",
    "mesg = Entry(master)\n",
    "\n",
    "mesg.grid(row=0, column=1)\n",
    "\n",
    "Button(master, text='Quit', command=master.destroy).grid(row=3, column=0, sticky=W, pady=4)\n",
    "Button(master, text='Enter', command=Recomend_Emoji).grid(row=3, column=1, sticky=W, pady=4)\n",
    "\n",
    "mainloop( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
