{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acuracy:  0.499330655957162\n"
     ]
    }
   ],
   "source": [
    "#William Dahl\n",
    "#CSI 436\n",
    "#Final Project\n",
    "#May 9th, 2019\n",
    "\n",
    "#This is a Regression model using the mode of a distrobution of given classes to predict an emoji\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Breaks up the data into training and testing data as well as sperated the messages from the classes\n",
    "def break_up_data():\n",
    "    with open('data.txt', 'r') as data:\n",
    "        i = 0\n",
    "        \n",
    "        #Makes the trainign data\n",
    "        train = open('train_data.txt', 'w') #the messages to be used to train the model\n",
    "        sentiment_train = open('sentiment_train.txt', 'w') #The classes of the messages int he triaing model\n",
    "        \n",
    "        #writes 80% of the messages to the training data\n",
    "        #there are 7480 messages in total\n",
    "        while i < 7480 * .8:\n",
    "            line = data.readline()\n",
    "            sentiment = line[1:28]\n",
    "            message = line[30:]\n",
    "            train.write(message.lower())\n",
    "            sentiment_train.write(sentiment)\n",
    "            sentiment_train.write(';')\n",
    "            i += 1\n",
    "        \n",
    "        #gets last line\n",
    "        #ensures there is not a empty space in the files\n",
    "        line = data.readline()\n",
    "        sentiment = line[1:28]\n",
    "        message = line[30:len(line)-2]\n",
    "        train.write(message.lower())\n",
    "        sentiment_train.write(sentiment)\n",
    "        i += 1\n",
    "        \n",
    "        #makes the testing data\n",
    "        test = open('test_data.txt', 'w') #messages to be used for testing\n",
    "        sentiment_test = open('sentiment_test.txt', 'w') #classes of the messages used in testing\n",
    "        line = data.readline()\n",
    "        \n",
    "        #adds the remaing 20% of the data to the testing files\n",
    "        while i < 7479:\n",
    "            line = data.readline()\n",
    "            sentiment = line[1:28]\n",
    "            message = line[30:]\n",
    "            test.write(message.lower())\n",
    "            sentiment_test.write(sentiment)\n",
    "            sentiment_test.write(';')\n",
    "            line = data.readline()\n",
    "            i += 1\n",
    "        \n",
    "        #gets last line to add to the testing file\n",
    "        #ensures there is not a empty space in the files\n",
    "        line = data.readline()\n",
    "        sentiment = line[1:28]\n",
    "        message = line[30:len(line)-2]\n",
    "        test.write(message.lower())\n",
    "        sentiment_test.write(sentiment)\n",
    "        \n",
    "#retrives the sentiment classes for the tringin data and stores it in the form of a matrix        \n",
    "def get_sentiment_matrix():\n",
    "    return np.matrix(open('sentiment_train.txt').read())\n",
    "\n",
    "#Breaks the message into 1-grams to 4-grams\n",
    "def create_n_grams(message):\n",
    "    message_list = message.split()\n",
    "    output = list()\n",
    "    #loops through message\n",
    "    for i in range(len(message_list)):\n",
    "        #greates the 1-grams to 4-grams of the message\n",
    "        for j in range(4):  \n",
    "            gram = message_list[i]\n",
    "            #makes the specifeid n-gram\n",
    "            for k in range(j):\n",
    "                if (i+k+1) < len(message_list):\n",
    "                    gram += \" \" + message_list[i+k+1]\n",
    "        \n",
    "            #checks if the gram was already created by an earlier message\n",
    "            if gram not in output:\n",
    "                output.append(gram)\n",
    "    \n",
    "    return output\n",
    "\n",
    "#determeins the overall class that each n-gram should belong too. \n",
    "def classify_n_grams():\n",
    "    train_data = open('train_data.txt', 'r')#data\n",
    "    sentiment_matrix = get_sentiment_matrix()#classes\n",
    "    message = train_data.readline()\n",
    "    classified_grams = dict()#our model\n",
    "    i = 0\n",
    "    \n",
    "    #Creates the n-grams for the message \n",
    "    while len(message) > 1:\n",
    "        grams = create_n_grams(message)\n",
    "        #adds the class of the mesage to the list of classes for the n-gram\n",
    "        for gram in grams:\n",
    "            #adds the n-gram to the dictonary if it is not already in it\n",
    "            if gram not in classified_grams:\n",
    "                classified_grams[gram] = list()\n",
    "            \n",
    "            #adds the class to the value list of the n-gram\n",
    "            for j in range(7):\n",
    "                if sentiment_matrix[i, j] == 1:\n",
    "                    classified_grams[gram].append(j)\n",
    "        \n",
    "        message = train_data.readline()\n",
    "        i += 1\n",
    "\n",
    "    #gets the Expected class value from the list of the classes in the file for the n-gram\n",
    "    #sets the overall class for the n-gram to be the expected value of the class for the n-gram\n",
    "    for gram in classified_grams:\n",
    "        classified_grams[gram] = max(set(classified_grams[gram]), key=classified_grams[gram].count)\n",
    "    \n",
    "    return classified_grams\n",
    "\n",
    "#classifes a given message based on the trained model classified_grams\n",
    "def classify_message(message, classified_grams):\n",
    "    grams = create_n_grams(message.lower()) #gets the n-grams from the given message\n",
    "    gram_class = list() #distrobution of classes from each n-gram extracted from the message\n",
    "    \n",
    "    #loops through the n-grams extracted from the message\n",
    "    for gram in grams:\n",
    "        #if the n-gram is a key in our model\n",
    "        if gram in classified_grams:\n",
    "            #writes the class of the n-gram to the class ditrobution for the message\n",
    "            for i in range(len(gram)):\n",
    "                gram_class.append(classified_grams[gram])\n",
    "                \n",
    "    if len(gram_class) == 0:\n",
    "        return 0\n",
    "    \n",
    "    #returns the class that appears the most in the ditrobution. \n",
    "    return max(set(gram_class), key=gram_class.count)\n",
    "\n",
    "#Begein exectuing our model\n",
    "#creates our model\n",
    "classified_grams = classify_n_grams()\n",
    "\n",
    "#loops trough the testing data to classify it\n",
    "with open('test_data.txt', 'r') as test:\n",
    "    #classes of the messages for testing\n",
    "    S_matrix = np.matrix(open('sentiment_test.txt').read())\n",
    "    wrong_count = 0 #keeps track of the wrongly classifed messages\n",
    "    i = 0\n",
    "    \n",
    "    #classifys all of the messages\n",
    "    for message in test:\n",
    "        clas = classify_message(message, classified_grams)\n",
    "        #checks of the class is wrong\n",
    "        if S_matrix[i,clas] != 1:\n",
    "            wrong_count += 1\n",
    "        \n",
    "        i += 1\n",
    "     \n",
    "    #acuraccy of the model\n",
    "    print(\"test acuracy: \", 1-wrong_count/747)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
